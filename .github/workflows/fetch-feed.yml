name: Fetch and Clean RSS Feed

on:
  schedule:
    - cron: '0 */6 * * *'
  workflow_dispatch:name: Fetch and Clean RSS Feed

on:
  schedule:
    - cron: '0 */6 * * *'
  workflow_dispatch:

jobs:
  fetch:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'
      
      - name: Install dependencies
        run: |
          pip install lxml requests beautifulsoup4
      
      - name: Fetch and Clean RSS Feed
        run: |
          python3 << 'EOF'
          import requests
          from lxml import etree
          from bs4 import BeautifulSoup
          from datetime import datetime, timezone
          import re
          from urllib.parse import quote

          print("Fetching original feed...")
          response = requests.get('https://www.cabletv.com/feed')
          root = etree.fromstring(response.content)
          channel = root.find('channel')
          items = channel.findall('item')[:8]
          
          nsmap = {
              'content': 'http://purl.org/rss/1.0/modules/content/',
              'wfw': 'http://wellformedweb.org/CommentAPI/',
              'dc': 'http://purl.org/dc/elements/1.1/',
              'atom': 'http://www.w3.org/2005/Atom',
              'sy': 'http://purl.org/rss/1.0/modules/syndication/',
              'slash': 'http://purl.org/rss/1.0/modules/slash/',
              'media': 'http://search.yahoo.com/mrss/',
              'snf': 'http://www.smartnews.be/snf'
          }
          
          for prefix, uri in nsmap.items():
              etree.register_namespace(prefix, uri)
          
          fallback_thumbnail = 'https://ctv-clearlink.github.io/RSS-Feed/CableTV.com%20RSS%20Logo%20Header.png'
          
          # Build XML
          xml_parts = []
          xml_parts.append('<?xml version="1.0" encoding="UTF-8"?>')
          xml_parts.append('<rss version="2.0"')
          xml_parts.append(' xmlns:content="http://purl.org/rss/1.0/modules/content/"')
          xml_parts.append(' xmlns:wfw="http://wellformedweb.org/CommentAPI/"')
          xml_parts.append(' xmlns:dc="http://purl.org/dc/elements/1.1/"')
          xml_parts.append(' xmlns:atom="http://www.w3.org/2005/Atom"')
          xml_parts.append(' xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"')
          xml_parts.append(' xmlns:slash="http://purl.org/rss/1.0/modules/slash/"')
          xml_parts.append(' xmlns:media="http://search.yahoo.com/mrss/"')
          xml_parts.append(' xmlns:snf="http://www.smartnews.be/snf">')
          xml_parts.append('<channel>')
          
          # Add channel metadata
          for elem in channel:
              if elem.tag == 'item':
                  break
              if 'logo' not in elem.tag.lower():
                  xml_parts.append(etree.tostring(elem, encoding='unicode', method='xml'))
              
              if elem.tag == 'description':
                  logo_url = f'https://ctv-clearlink.github.io/RSS-Feed/{quote("CableTV.com RSS Logo Header.png")}'
                  xml_parts.append(f'<snf:logo>{logo_url}</snf:logo>')
          
          cdata_count = 0
          
          def fetch_og_image(article_url):
              """Fetch the og:image from the article page"""
              try:
                  headers = {
                      'User-Agent': 'Mozilla/5.0 (compatible; SmartFeed-Builder/3.0)',
                      'Accept': 'text/html'
                  }
                  response = requests.get(article_url, headers=headers, timeout=10)
                  if response.ok:
                      # Look for og:image meta tag
                      match = re.search(r'<meta[^>]+property=["\']og:image["\'][^>]+content=["\']([^"\']+)["\']', response.text, re.IGNORECASE)
                      if match:
                          return match.group(1)
              except Exception as e:
                  print(f"    ! Error fetching {article_url}: {e}")
              return None
          
          for idx, item in enumerate(items):
              title_text = item.find('title').text if item.find('title') is not None else 'Unknown'
              print(f"\n{'='*60}")
              print(f"Item {idx+1}: {title_text[:50]}")
              
              xml_parts.append('<item>')
              
              original_content = None
              article_link = None
              
              # Get link and content
              for elem in item:
                  if elem.tag == 'link':
                      article_link = elem.text.split('?')[0] if elem.text else None
                  
                  tag_name = etree.QName(elem.tag).localname if '}' in elem.tag else elem.tag
                  namespace = etree.QName(elem.tag).namespace if '}' in elem.tag else None
                  
                  if namespace == 'http://purl.org/rss/1.0/modules/content/' and tag_name == 'encoded':
                      original_content = elem.text or ''
              
              # Process all elements EXCEPT media:thumbnail
              for elem in item:
                  tag_name = etree.QName(elem.tag).localname if '}' in elem.tag else elem.tag
                  namespace = etree.QName(elem.tag).namespace if '}' in elem.tag else None
                  
                  # Skip existing thumbnails
                  if namespace == 'http://search.yahoo.com/mrss/':
                      continue
                  
                  if namespace == 'http://purl.org/rss/1.0/modules/content/' and tag_name == 'encoded':
                      if original_content:
                          soup = BeautifulSoup(original_content, 'html.parser')
                          links = soup.find_all('a')
                          if len(links) > 3:
                              for link in links[3:]:
                                  link.unwrap()
                          content_html = str(soup)
                          xml_parts.append(f'<content:encoded><![CDATA[{content_html}]]></content:encoded>')
                          cdata_count += 1
                  else:
                      xml_parts.append(etree.tostring(elem, encoding='unicode', method='xml'))
              
              # Add required fields
              if item.find('dc:creator', nsmap) is None:
                  xml_parts.append('<dc:creator>CableTV.com</dc:creator>')
              
              if item.find('pubDate') is None:
                  xml_parts.append(f'<pubDate>{datetime.now(timezone.utc).strftime("%a, %d %b %Y %H:%M:%S +0000")}</pubDate>')
              
              # FETCH THE FEATURED IMAGE FROM THE ARTICLE PAGE
              featured_image = None
              if article_link:
                  print(f"  Fetching og:image from: {article_link}")
                  featured_image = fetch_og_image(article_link)
                  if featured_image:
                      print(f"  ✓ Found og:image: {featured_image.split('/')[-1]}")
                  else:
                      print(f"  ! No og:image found")
              
              # Use featured image or fallback
              if not featured_image:
                  featured_image = fallback_thumbnail
                  print(f"  Using fallback thumbnail")
              
              # Sanitize URL
              if not featured_image.startswith('http'):
                  if featured_image.startswith('//'):
                      featured_image = 'https:' + featured_image
                  elif featured_image.startswith('/'):
                      featured_image = 'https://www.cabletv.com' + featured_image
              
              featured_image = featured_image.replace('&', '&amp;')
              
              xml_parts.append(f'<media:thumbnail url="{featured_image}"/>')
              xml_parts.append('</item>')
          
          xml_parts.append('</channel></rss>')
          xml_string = ''.join(xml_parts).replace('https://www.cabletv.com/feed', 'https://ctv-clearlink.github.io/RSS-Feed/feed.xml')
          
          with open('feed.xml', 'w', encoding='utf-8') as f:
              f.write(xml_string)
          
          print(f"\n{'='*60}")
          print(f"✓ Feed created with {cdata_count} CDATA sections")
          print(f"✓ Output size: {len(xml_string):,} bytes ({len(xml_string)/1024/1024:.2f} MB)")
          EOF
      
      - name: Check for changes
        id: changes
        run: |
          git diff --quiet feed.xml || echo "changed=true" >> $GITHUB_OUTPUT
      
      - name: Commit and push feed
        if: steps.changes.outputs.changed == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add feed.xml
          git commit -m "Update RSS feed $(date '+%Y-%m-%d %H:%M:%S')"
          git pull --rebase origin main
          git push origin main

jobs:
  fetch:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'
      
      - name: Install dependencies
        run: |
          pip install lxml requests beautifulsoup4
      
      - name: Debug original feed structure
        run: |
          python3 << 'EOF'
          import requests
          from lxml import etree
          
          response = requests.get('https://www.cabletv.com/feed')
          root = etree.fromstring(response.content)
          
          # Check first item for all available fields
          channel = root.find('channel')
          first_item = channel.find('item')
          
          print("=== First Item Structure ===")
          print(f"Title: {first_item.find('title').text if first_item.find('title') is not None else 'N/A'}")
          print("\nAll elements in first item:")
          for elem in first_item:
                tag = etree.QName(elem.tag).localname if '}' in elem.tag else elem.tag
                namespace = etree.QName(elem.tag).namespace if '}' in elem.tag else 'default'
                print(f"  - {namespace}:{tag}")
                
                # Check for media or image-related tags
                if 'media' in tag.lower() or 'image' in tag.lower() or 'enclosure' in tag.lower():
                    print(f"    → {elem.attrib if elem.attrib else elem.text[:100] if elem.text else 'empty'}")
          
          print("\n=== Checking for media:content or media:thumbnail ===")
          nsmap = {'media': 'http://search.yahoo.com/mrss/'}
          media_content = first_item.findall('media:content', nsmap)
          media_thumbnail = first_item.findall('media:thumbnail', nsmap)
          
          print(f"media:content found: {len(media_content)}")
          for mc in media_content:
              print(f"  URL: {mc.get('url')}")
          
          print(f"media:thumbnail found: {len(media_thumbnail)}")
          for mt in media_thumbnail:
              print(f"  URL: {mt.get('url')}")
          
          # Check enclosure
          enclosure = first_item.find('enclosure')
          if enclosure is not None:
              print(f"\nEnclosure: {enclosure.get('url')} (type: {enclosure.get('type')})")
          
          EOF
      
      - name: Fetch and Clean RSS Feed
        run: |
          python3 << 'EOF'
          import requests
          from lxml import etree
          from bs4 import BeautifulSoup
          from datetime import datetime, timezone
          import re
          from urllib.parse import quote

          print("Fetching original feed...")
          response = requests.get('https://www.cabletv.com/feed')
          root = etree.fromstring(response.content)
          channel = root.find('channel')
          items = channel.findall('item')[:8]
          
          nsmap = {
              'content': 'http://purl.org/rss/1.0/modules/content/',
              'wfw': 'http://wellformedweb.org/CommentAPI/',
              'dc': 'http://purl.org/dc/elements/1.1/',
              'atom': 'http://www.w3.org/2005/Atom',
              'sy': 'http://purl.org/rss/1.0/modules/syndication/',
              'slash': 'http://purl.org/rss/1.0/modules/slash/',
              'media': 'http://search.yahoo.com/mrss/',
              'snf': 'http://www.smartnews.be/snf'
          }
          
          for prefix, uri in nsmap.items():
              etree.register_namespace(prefix, uri)
          
          fallback_thumbnail = 'https://ctv-clearlink.github.io/RSS-Feed/CableTV.com%20RSS%20Logo%20Header.png'
          
          # Build XML
          xml_parts = []
          xml_parts.append('<?xml version="1.0" encoding="UTF-8"?>')
          xml_parts.append('<rss version="2.0"')
          xml_parts.append(' xmlns:content="http://purl.org/rss/1.0/modules/content/"')
          xml_parts.append(' xmlns:wfw="http://wellformedweb.org/CommentAPI/"')
          xml_parts.append(' xmlns:dc="http://purl.org/dc/elements/1.1/"')
          xml_parts.append(' xmlns:atom="http://www.w3.org/2005/Atom"')
          xml_parts.append(' xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"')
          xml_parts.append(' xmlns:slash="http://purl.org/rss/1.0/modules/slash/"')
          xml_parts.append(' xmlns:media="http://search.yahoo.com/mrss/"')
          xml_parts.append(' xmlns:snf="http://www.smartnews.be/snf">')
          xml_parts.append('<channel>')
          
          # Add channel metadata
          for elem in channel:
              if elem.tag == 'item':
                  break
              if 'logo' not in elem.tag.lower():
                  xml_parts.append(etree.tostring(elem, encoding='unicode', method='xml'))
              
              if elem.tag == 'description':
                  logo_url = f'https://ctv-clearlink.github.io/RSS-Feed/{quote("CableTV.com RSS Logo Header.png")}'
                  xml_parts.append(f'<snf:logo>{logo_url}</snf:logo>')
          
          cdata_count = 0
          
          for idx, item in enumerate(items):
              title_text = item.find('title').text if item.find('title') is not None else 'Unknown'
              print(f"\nItem {idx+1}: {title_text[:50]}")
              
              xml_parts.append('<item>')
              
              original_content = None
              featured_image = None
              
              # FIRST: Check if there's already a media:thumbnail or media:content in original
              existing_media_thumb = item.find('media:thumbnail', nsmap)
              existing_media_content = item.find('media:content', nsmap)
              existing_enclosure = item.find('enclosure')
              
              if existing_media_thumb is not None:
                  featured_image = existing_media_thumb.get('url')
                  print(f"  ✓ Found existing media:thumbnail: {featured_image.split('/')[-1]}")
              elif existing_media_content is not None:
                  featured_image = existing_media_content.get('url')
                  print(f"  ✓ Found existing media:content: {featured_image.split('/')[-1]}")
              elif existing_enclosure is not None and 'image' in existing_enclosure.get('type', ''):
                  featured_image = existing_enclosure.get('url')
                  print(f"  ✓ Found image enclosure: {featured_image.split('/')[-1]}")
              
              # Get content
              for elem in item:
                  tag_name = etree.QName(elem.tag).localname if '}' in elem.tag else elem.tag
                  namespace = etree.QName(elem.tag).namespace if '}' in elem.tag else None
                  
                  if namespace == 'http://purl.org/rss/1.0/modules/content/' and tag_name == 'encoded':
                      original_content = elem.text or ''
              
              # Process all elements EXCEPT media:thumbnail (we'll add our own)
              for elem in item:
                  tag_name = etree.QName(elem.tag).localname if '}' in elem.tag else elem.tag
                  namespace = etree.QName(elem.tag).namespace if '}' in elem.tag else None
                  
                  # Skip media:thumbnail and media:content - we'll add fresh ones
                  if namespace == 'http://search.yahoo.com/mrss/':
                      continue
                  
                  if namespace == 'http://purl.org/rss/1.0/modules/content/' and tag_name == 'encoded':
                      if original_content:
                          soup = BeautifulSoup(original_content, 'html.parser')
                          links = soup.find_all('a')
                          if len(links) > 3:
                              for link in links[3:]:
                                  link.unwrap()
                          content_html = str(soup)
                          xml_parts.append(f'<content:encoded><![CDATA[{content_html}]]></content:encoded>')
                          cdata_count += 1
                  else:
                      xml_parts.append(etree.tostring(elem, encoding='unicode', method='xml'))
              
              # Add required fields
              if item.find('dc:creator', nsmap) is None:
                  xml_parts.append('<dc:creator>CableTV.com</dc:creator>')
              
              if item.find('pubDate') is None:
                  xml_parts.append(f'<pubDate>{datetime.now(timezone.utc).strftime("%a, %d %b %Y %H:%M:%S +0000")}</pubDate>')
              
              # Use the featured image we found, or fallback
              if featured_image:
                  if not featured_image.startswith('http'):
                      if featured_image.startswith('//'):
                          featured_image = 'https:' + featured_image
                      elif featured_image.startswith('/'):
                          featured_image = 'https://www.cabletv.com' + featured_image
                  featured_image = featured_image.replace('&', '&amp;')
              else:
                  featured_image = fallback_thumbnail
                  print(f"  ! No featured image found, using fallback")
              
              xml_parts.append(f'<media:thumbnail url="{featured_image}"/>')
              xml_parts.append('</item>')
          
          xml_parts.append('</channel></rss>')
          xml_string = ''.join(xml_parts).replace('https://www.cabletv.com/feed', 'https://ctv-clearlink.github.io/RSS-Feed/feed.xml')
          
          with open('feed.xml', 'w', encoding='utf-8') as f:
              f.write(xml_string)
          
          print(f"\n✓ Feed created with {cdata_count} CDATA sections")
          EOF
      
      - name: Check for changes
        id: changes
        run: |
          git diff --quiet feed.xml || echo "changed=true" >> $GITHUB_OUTPUT
      
      - name: Commit and push feed
        if: steps.changes.outputs.changed == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add feed.xml
          git commit -m "Update RSS feed $(date '+%Y-%m-%d %H:%M:%S')"
          git pull --rebase origin main
          git push origin main
