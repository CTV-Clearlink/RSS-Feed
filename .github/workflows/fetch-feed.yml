name: Fetch and Clean RSS Feed

on:
  schedule:
    - cron: '0 */6 * * *'
  workflow_dispatch:

jobs:
  fetch:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'
      
      - name: Install dependencies
        run: |
          pip install lxml requests beautifulsoup4
      
      - name: Fetch and Clean RSS Feed
        run: |
          python3 << 'EOF'
          import requests
          from lxml import etree
          from bs4 import BeautifulSoup
          from datetime import datetime
          import re
          from urllib.parse import quote
          import html

          # Fetch the original feed
          print("Fetching original feed...")
          response = requests.get('https://www.cabletv.com/feed')
          
          # Parse the XML
          root = etree.fromstring(response.content)
          
          # Get the channel element
          channel = root.find('channel')
          
          # Define namespace map
          nsmap = {
              'content': 'http://purl.org/rss/1.0/modules/content/',
              'wfw': 'http://wellformedweb.org/CommentAPI/',
              'dc': 'http://purl.org/dc/elements/1.1/',
              'atom': 'http://www.w3.org/2005/Atom',
              'sy': 'http://purl.org/rss/1.0/modules/syndication/',
              'slash': 'http://purl.org/rss/1.0/modules/slash/',
              'media': 'http://search.yahoo.com/mrss/',
              'snf': 'http://www.smartnews.be/snf'
          }
          
          # Register all namespaces
          for prefix, uri in nsmap.items():
              etree.register_namespace(prefix, uri)
          
          # Create new RSS document
          rss_attribs = {
              'version': '2.0',
              '{http://www.w3.org/2000/xmlns/}content': 'http://purl.org/rss/1.0/modules/content/',
              '{http://www.w3.org/2000/xmlns/}wfw': 'http://wellformedweb.org/CommentAPI/',
              '{http://www.w3.org/2000/xmlns/}dc': 'http://purl.org/dc/elements/1.1/',
              '{http://www.w3.org/2000/xmlns/}atom': 'http://www.w3.org/2005/Atom',
              '{http://www.w3.org/2000/xmlns/}sy': 'http://purl.org/rss/1.0/modules/syndication/',
              '{http://www.w3.org/2000/xmlns/}slash': 'http://purl.org/rss/1.0/modules/slash/',
              '{http://www.w3.org/2000/xmlns/}media': 'http://search.yahoo.com/mrss/',
              '{http://www.w3.org/2000/xmlns/}snf': 'http://www.smartnews.be/snf'
          }
          
          new_rss = etree.Element('rss', rss_attribs)
          new_channel = etree.SubElement(new_rss, 'channel')
          
          # URL encode the filename
          logo_filename = 'CableTV.com RSS Logo Header.png'
          logo_url_path = quote(logo_filename)
          logo_full_url = f'https://ctv-clearlink.github.io/RSS-Feed/{logo_url_path}'
          
          # Copy channel metadata and add logo
          logo_added = False
          for elem in channel:
              if elem.tag == 'item':
                  break
              tag_name = etree.QName(elem.tag).localname if '}' in elem.tag else elem.tag
              
              if 'logo' in tag_name.lower():
                  continue
                  
              new_channel.append(elem)
              
              if tag_name == 'description' and not logo_added:
                  snf_logo = etree.SubElement(new_channel, '{http://www.smartnews.be/snf}logo')
                  logo_url_elem = etree.SubElement(snf_logo, 'url')
                  logo_url_elem.text = logo_full_url
                  logo_added = True
                  print(f"✓ Added snf:logo")
          
          if not logo_added:
              snf_logo = etree.SubElement(new_channel, '{http://www.smartnews.be/snf}logo')
              logo_url_elem = etree.SubElement(snf_logo, 'url')
              logo_url_elem.text = logo_full_url
          
          # Store content for CDATA replacement
          content_map = {}
          item_index = 0
          
          # Process items
          items = channel.findall('item')
          print(f"Processing {len(items)} items...")
          
          for old_item in items:
              new_item = etree.SubElement(new_channel, 'item')
              
              content_text = None
              placeholder_id = f'CDATAPLACEHOLDER{item_index}'
              
              # Copy all elements from old item
              for elem in old_item:
                  tag_name = etree.QName(elem.tag).localname
                  namespace = etree.QName(elem.tag).namespace
                  
                  # Handle content:encoded specially
                  if namespace == 'http://purl.org/rss/1.0/modules/content/' and tag_name == 'encoded':
                      content_text = elem.text
                      
                      if content_text:
                          # Parse HTML and remove excessive links
                          soup = BeautifulSoup(content_text, 'html.parser')
                          links = soup.find_all('a')
                          if len(links) > 3:
                              for link in links[3:]:
                                  link.unwrap()
                          
                          cleaned_content = str(soup)
                          
                          # Store content for later CDATA insertion
                          content_map[placeholder_id] = cleaned_content
                          
                          # Create content:encoded with placeholder
                          new_content = etree.SubElement(new_item, '{http://purl.org/rss/1.0/modules/content/}encoded')
                          new_content.text = placeholder_id
                          
                          # Extract and add thumbnail
                          img_match = re.search(r'<img[^>]+src=["\']([^"\']+)["\']', cleaned_content)
                          if img_match:
                              img_url = img_match.group(1)
                              thumbnail = etree.SubElement(new_item, '{http://search.yahoo.com/mrss/}thumbnail')
                              thumbnail.set('url', img_url)
                  else:
                      # Copy other elements
                      new_elem = etree.SubElement(new_item, elem.tag, elem.attrib)
                      new_elem.text = elem.text
                      new_elem.tail = elem.tail
                      for child in elem:
                          new_elem.append(child)
              
              # Ensure required fields
              if new_item.find('dc:creator', nsmap) is None:
                  creator = etree.SubElement(new_item, '{http://purl.org/dc/elements/1.1/}creator')
                  creator.text = 'CableTV.com'
              
              if new_item.find('pubDate') is None:
                  pubdate = etree.SubElement(new_item, 'pubDate')
                  pubdate.text = datetime.utcnow().strftime('%a, %d %b %Y %H:%M:%S +0000')
              
              if new_item.find('description') is None and content_text:
                  description = etree.SubElement(new_item, 'description')
                  text_content = re.sub(r'<[^>]+>', '', content_text)
                  description.text = text_content.strip()[:200] + '...'
              
              item_index += 1
          
          # Convert to string
          xml_string = etree.tostring(new_rss, 
                                      pretty_print=True, 
                                      xml_declaration=True, 
                                      encoding='UTF-8',
                                      method='xml')
          
          xml_string = xml_string.decode('utf-8')
          
          # Now replace placeholders with proper CDATA
          for placeholder_id, content in content_map.items():
              # Find and replace the placeholder with CDATA wrapped content
              pattern = f'<content:encoded>{re.escape(placeholder_id)}</content:encoded>'
              replacement = f'<content:encoded><![CDATA[{content}]]></content:encoded>'
              xml_string = xml_string.replace(f'<content:encoded>{placeholder_id}</content:encoded>', replacement)
          
          # Fix atom:link self-reference
          xml_string = xml_string.replace(
              'https://www.cabletv.com/feed',
              'https://ctv-clearlink.github.io/RSS-Feed/feed.xml'
          )
          
          # Write to file
          with open('feed.xml', 'w', encoding='utf-8') as f:
              f.write(xml_string)
          
          print("✓ Feed cleaned with CDATA sections!")
          print(f"✓ Processed {len(content_map)} content:encoded elements")
          EOF
      
      - name: Verify CDATA sections
        run: |
          echo "Checking for CDATA sections in feed..."
          grep -c "CDATA" feed.xml || echo "No CDATA found - ERROR"
          
      - name: Check for changes
        id: changes
        run: |
          git diff --quiet feed.xml || echo "changed=true" >> $GITHUB_OUTPUT
      
      - name: Commit and push feed
        if: steps.changes.outputs.changed == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add feed.xml
          git commit -m "Update RSS feed $(date '+%Y-%m-%d %H:%M:%S')"
          git pull --rebase origin main
          git push origin main
