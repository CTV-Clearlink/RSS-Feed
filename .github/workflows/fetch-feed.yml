name: Fetch and Clean RSS Feed

on:
  schedule:
    - cron: '0 */6 * * *'
  workflow_dispatch:

jobs:
  fetch:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'
      
      - name: Install dependencies
        run: |
          pip install lxml requests beautifulsoup4
      
      - name: Fetch and Clean RSS Feed
        run: |
          python3 << 'EOF'
          import requests
          from lxml import etree
          from bs4 import BeautifulSoup
          from datetime import datetime
          import re

          # Fetch the original feed
          print("Fetching original feed...")
          response = requests.get('https://www.cabletv.com/feed')
          
          # Parse the XML
          root = etree.fromstring(response.content)
          
          # Get the channel element
          channel = root.find('channel')
          
          # Define namespace map
          nsmap = {
              'content': 'http://purl.org/rss/1.0/modules/content/',
              'wfw': 'http://wellformedweb.org/CommentAPI/',
              'dc': 'http://purl.org/dc/elements/1.1/',
              'atom': 'http://www.w3.org/2005/Atom',
              'sy': 'http://purl.org/rss/1.0/modules/syndication/',
              'slash': 'http://purl.org/rss/1.0/modules/slash/',
              'media': 'http://search.yahoo.com/mrss/',
              'snf': 'http://www.smartnews.be/snf'
          }
          
          # Register all namespaces
          for prefix, uri in nsmap.items():
              etree.register_namespace(prefix, uri)
          
          # Create new RSS document with ALL namespaces declared at root
          rss_attribs = {
              'version': '2.0',
              '{http://www.w3.org/2000/xmlns/}content': 'http://purl.org/rss/1.0/modules/content/',
              '{http://www.w3.org/2000/xmlns/}wfw': 'http://wellformedweb.org/CommentAPI/',
              '{http://www.w3.org/2000/xmlns/}dc': 'http://purl.org/dc/elements/1.1/',
              '{http://www.w3.org/2000/xmlns/}atom': 'http://www.w3.org/2005/Atom',
              '{http://www.w3.org/2000/xmlns/}sy': 'http://purl.org/rss/1.0/modules/syndication/',
              '{http://www.w3.org/2000/xmlns/}slash': 'http://purl.org/rss/1.0/modules/slash/',
              '{http://www.w3.org/2000/xmlns/}media': 'http://search.yahoo.com/mrss/',
              '{http://www.w3.org/2000/xmlns/}snf': 'http://www.smartnews.be/snf'
          }
          
          new_rss = etree.Element('rss', rss_attribs)
          new_channel = etree.SubElement(new_rss, 'channel')
          
          # Copy channel metadata elements in order
          logo_added = False
          for elem in channel:
              if elem.tag == 'item':
                  break
              tag_name = etree.QName(elem.tag).localname if '}' in elem.tag else elem.tag
              
              # Skip any existing logo
              if 'logo' in tag_name.lower():
                  continue
                  
              new_channel.append(elem)
              
              # Add logo with proper structure right after description
              if tag_name == 'description' and not logo_added:
                  # Create snf:logo with nested url element
                  snf_logo = etree.SubElement(new_channel, '{http://www.smartnews.be/snf}logo')
                  logo_url = etree.SubElement(snf_logo, 'url')
                  logo_url.text = 'https://i.ibb.co/Y6Z731Z/RSS-Logo-Header.png'
                  logo_added = True
                  print("✓ Added snf:logo with <url> subelement")
          
          # If we didn't add logo yet, add it now
          if not logo_added:
              snf_logo = etree.SubElement(new_channel, '{http://www.smartnews.be/snf}logo')
              logo_url = etree.SubElement(snf_logo, 'url')
              logo_url.text = 'https://i.ibb.co/Y6Z731Z/RSS-Logo-Header.png'
              print("✓ Added snf:logo as fallback")
          
          # Process items
          items = channel.findall('item')
          print(f"Processing {len(items)} items...")
          
          for old_item in items:
              new_item = etree.SubElement(new_channel, 'item')
              
              content_text = None
              
              # Copy all elements from old item
              for elem in old_item:
                  tag_name = etree.QName(elem.tag).localname
                  namespace = etree.QName(elem.tag).namespace
                  
                  # Handle content:encoded specially
                  if namespace == 'http://purl.org/rss/1.0/modules/content/' and tag_name == 'encoded':
                      content_text = elem.text
                      
                      if content_text:
                          # Parse HTML and remove excessive links (keep only first 3)
                          soup = BeautifulSoup(content_text, 'html.parser')
                          links = soup.find_all('a')
                          if len(links) > 3:
                              for link in links[3:]:
                                  link.unwrap()
                          
                          cleaned_content = str(soup)
                          
                          # Create new content:encoded - DON'T add text yet, we'll do CDATA later
                          new_content = etree.SubElement(new_item, '{http://purl.org/rss/1.0/modules/content/}encoded')
                          new_content.text = '###CDATA_PLACEHOLDER###' + cleaned_content + '###CDATA_END###'
                          
                          # Extract and add thumbnail
                          img_match = re.search(r'<img[^>]+src=["\']([^"\']+)["\']', cleaned_content)
                          if img_match:
                              img_url = img_match.group(1)
                              thumbnail = etree.SubElement(new_item, '{http://search.yahoo.com/mrss/}thumbnail')
                              thumbnail.set('url', img_url)
                  else:
                      # Copy other elements as-is
                      new_elem = etree.SubElement(new_item, elem.tag, elem.attrib)
                      new_elem.text = elem.text
                      new_elem.tail = elem.tail
                      for child in elem:
                          new_elem.append(child)
              
              # Ensure required fields exist
              if new_item.find('dc:creator', nsmap) is None:
                  creator = etree.SubElement(new_item, '{http://purl.org/dc/elements/1.1/}creator')
                  creator.text = 'CableTV.com'
              
              if new_item.find('pubDate') is None:
                  pubdate = etree.SubElement(new_item, 'pubDate')
                  pubdate.text = datetime.utcnow().strftime('%a, %d %b %Y %H:%M:%S +0000')
              
              if new_item.find('description') is None and content_text:
                  description = etree.SubElement(new_item, 'description')
                  text_content = re.sub(r'<[^>]+>', '', content_text)
                  description.text = text_content.strip()[:200] + '...'
          
          # Convert to string
          xml_string = etree.tostring(new_rss, 
                                      pretty_print=True, 
                                      xml_declaration=True, 
                                      encoding='UTF-8',
                                      method='xml')
          
          xml_string = xml_string.decode('utf-8')
          
          # Replace placeholders with proper CDATA
          xml_string = re.sub(
              r'<content:encoded>###CDATA_PLACEHOLDER###(.*?)###CDATA_END###</content:encoded>',
              lambda m: f'<content:encoded><![CDATA[{m.group(1)}]]></content:encoded>',
              xml_string,
              flags=re.DOTALL
          )
          
          # Fix atom:link self-reference
          xml_string = xml_string.replace(
              'https://www.cabletv.com/feed',
              'https://ctv-clearlink.github.io/RSS-Feed/feed.xml'
          )
          
          # Write to file
          with open('feed.xml', 'w', encoding='utf-8') as f:
              f.write(xml_string)
          
          print("Feed cleaned successfully!")
          print("Check the feed for: <snf:logo><url>...")
          EOF
      
      - name: Verify logo in feed
        run: |
          echo "Checking if logo exists in feed..."
          grep -o '<snf:logo>.*</snf:logo>' feed.xml | head -5 || echo "Logo not found"
          
      - name: Check for changes
        id: changes
        run: |
          git diff --quiet feed.xml || echo "changed=true" >> $GITHUB_OUTPUT
      
      - name: Commit and push feed
        if: steps.changes.outputs.changed == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add feed.xml
          git commit -m "Update RSS feed $(date '+%Y-%m-%d %H:%M:%S')"
          git pull --rebase origin main
          git push origin main
